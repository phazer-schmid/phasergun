# API Server Environment Variables

# Anthropic API Key
# Get your API key from: https://console.anthropic.com/
# This is required for real LLM analysis
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Server Configuration
PORT=3001

# LLM Configuration
# Options: "anthropic", "mistral", "ollama" (local/free), or "mock" (testing)
LLM_MODE=mock

# Anthropic Configuration (for LLM_MODE=anthropic)
# Cost Optimized Setup (Recommended):
# - claude-3-haiku-20240307: ULTRA COST-EFFECTIVE! $0.25/$1.25 per 1M tokens (input/output)
#   Perfect for generating critical recommendations. 98% cost savings vs Sonnet.
# 
# High Quality Setup (For complex analysis):
# - claude-3-5-sonnet-20241022: Premium quality. $3/$15 per 1M tokens (input/output)
#   Use only when you need detailed reasoning and explanations.
#
# Current setup optimized for: Critical recommendations only (max 500 tokens output)
ANTHROPIC_MODEL=claude-3-haiku-20240307

# Mistral AI Configuration (for LLM_MODE=mistral)
# Get your API key from: https://console.mistral.ai/
# Cost-Effective Setup (Recommended):
# - mistral-small-latest: BEST VALUE! $0.20/$0.60 per 1M tokens (input/output)
#   Even cheaper than Claude Haiku! Perfect for compliance analysis.
#   50% cheaper than Haiku, 97% cheaper than Sonnet.
#
# High Quality Setup:
# - mistral-medium-latest: $2.50/$7.50 per 1M tokens (input/output)
#   Use for more complex reasoning tasks.
MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_MODEL=mistral-small-latest

# Ollama Configuration (for LLM_MODE=ollama)
# Recommended models:
# - llama3.1:70b (best quality for FDA compliance, needs 48GB RAM)
# - llama3.1:8b (faster, lower quality, needs 8GB RAM)
# - qwen2.5:72b (alternative to llama, needs 48GB RAM)
# - mixtral:8x7b (good balance, needs 24GB RAM)
OLLAMA_MODEL=llama3.1:70b
OLLAMA_BASE_URL=http://localhost:11434
