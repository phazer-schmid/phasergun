# API Server Environment Variables

# Server Configuration
PORT=3001

# LLM Configuration
LLM_MODE=mock
# Options: anthropic, mistral, groq, ollama, mock

# Anthropic API Configuration
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-sonnet-4-20250514
# Options: claude-sonnet-4-20250514, claude-3-5-sonnet-20241022, claude-3-haiku-20240307

# Mistral API Configuration (optional)
MISTRAL_API_KEY=
MISTRAL_MODEL=mistral-small-latest

# Groq API Configuration (optional)
GROQ_API_KEY=
GROQ_MODEL=llama-3.1-8b-instant

# Ollama Configuration (optional)
OLLAMA_MODEL=llama3.1:70b
OLLAMA_BASE_URL=http://localhost:11434

# Primary Context Path
# Path to primary-context.yaml file
# If not set, defaults to: src/rag-service/knowledge-base/context/primary-context.yaml
PRIMARY_CONTEXT_PATH=

# Cache Configuration
# Set to false to disable all caching (vector store, summaries, metadata)
# When disabled, all documents are processed fresh on every request (slower but always up-to-date)
# Useful for development/debugging or when content changes frequently
# Default: true (caching enabled for performance)
CACHE_ENABLED=true
